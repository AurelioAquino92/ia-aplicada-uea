{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade Prática 2.1 - Cobertura Florestal\n",
    "\n",
    "* Disciplina _Inteligência Artificial Aplicada_\n",
    "* Professora: Elloá B. Guedes (ebgcosta@uea.edu.br)\n",
    "* Data de apresentação: 26 de janeiro de 2024\n",
    "* Data limite de entrega: 01 de fevereiro de 2024\n",
    "\n",
    "\n",
    "## Equipe\n",
    "* Integrante 1: *Aurelio Aquino*\n",
    "* Integrante 2: *Jailson Bina*\n",
    "* Integrante 3: *Sthephany Costa*\n",
    "* Integrante 4: *Erica Veras*\n",
    "* Integrante 5: *Michelle de Carvalho*\n",
    "* Integrante 6: *Fabiano Dolzanes*\n",
    "\n",
    "\n",
    "## Contexto: Cobertura Florestal\n",
    "\n",
    "Este conjunto de dados contém observações de árvores de quatro áreas da Floresta Nacional de Roosevelt, no Colorado. Todas as observações são variáveis cartográficas (sem sensoriamento remoto) de seções de floresta de 30 metros por 30 metros. Há mais de meio milhão de medições no total\n",
    "\n",
    "## Base de Dados\n",
    "\n",
    "Disponível em: https://www.kaggle.com/datasets/uciml/forest-cover-type-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas\n",
    "\n",
    "Por hábito, a primeira célula do notebook costuma ser reservada para importação de bibliotecas.\n",
    "A cada biblioteca nova acrescida, é necessário executar a célula para atualização e correta execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abertura do Dataset\n",
    "\n",
    "Abra o dataset e visualize o seu cabeçalho, isto é, os primeiros exemplos nele contidos.\n",
    "Isto é útil para checar se a importação foi realizada de maneira adequada e se a disposição dos dados está de acordo para os próximos passos do trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('covtype2 - covtype2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise Exploratória\n",
    "\n",
    "1. Quantos exemplos há no dataset?\n",
    "2. Quais os atributos existentes no dataset?\n",
    "3. O atributo alvo é Cover_Type. A distribuição de classes no mesmo é uniforme?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cover_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organização dos dados para treinamento\n",
    "\n",
    "1. Remova os dados faltantes\n",
    "2. Remova a coluna Cover_Type e atribua-a a uma variável Y\n",
    "3. Atribua os demais valores do dataset a uma variável X\n",
    "4. Efetue uma partição holdout 70/30 com o sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Cover_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento de uma RNA MLP para o problema\n",
    "\n",
    "1. Treine uma RNA MLP Classificadora para este problema com uma única camada e 10 neurônios  \n",
    "    1.1 Utilize a função de ativação ReLU  \n",
    "    1.2 Utilize o solver Adam    \n",
    "    1.3 Imprima o passo a passo do treinamento    \n",
    "    1.4 Utilize o número máximo de épocas igual a 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', solver='adam', verbose=True, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aferição de Desempenho\n",
    "\n",
    "2. Com o modelo em questão, após o treinamento, apresente:  \n",
    "    2.1 Matriz de confusão para o conjunto de teste  \n",
    "    2.2 Acurácia  \n",
    "    2.3 F-Score Balanceado  \n",
    "    2.4 Precisão  \n",
    "    2.5 Revocação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prev = modelo.predict(X_test)\n",
    "ConfusionMatrixDisplay.from_predictions(Y_test, Y_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_test, Y_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(Y_test, Y_prev, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(Y_test, Y_prev, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(Y_test, Y_prev, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca em Grade\n",
    "\n",
    "Uma maneira padrão de escolher os parâmetros de um modelo de Machine Learning é por meio de uma busca em grade via força bruta. O algoritmo da busca em grade é dado como segue:\n",
    "\n",
    "1. Escolha a métrica de desempenho que você deseja maximizar  \n",
    "2. Escolha o algoritmo de Machine Learning (exemplo: redes neurais artificiais). Em seguida, defina os parâmetros ou hiperparâmetros deste tipo de modelo sobre os quais você dseja otimizar (número de épocas, taxa de aprendizado, etc.) e construa um array de valores a serem testados para cada parâmetro ou hiperparâmetro.  \n",
    "3. Defina a grade de busca, a qual é dada como o produto cartesiano de cada parâmetro a ser testado. Por exemplo, para os arrays [50, 75, 100] e [10, 15], tem-se que a grade é [(50,10), (50,15), (75,10), (75,15), (100,10), (100,15)].\n",
    "4. Para cada combinação de parâmetros a serem otimizados, utilize o conjunto de treinamento para realizar uma validação cruzada (holdout ou k-fold) e calcule a métrica de avaliação no conjunto de teste (ou conjuntos de teste)\n",
    "5. Escolha a combinação de parâmetros que maximizam a métrica de avaliação. Este é o modelo otimizado.\n",
    "\n",
    "Por que esta abordagem funciona? Porque a busca em grade efetua uma pesquisa extensiva sobre as possíveis combinações de valores para cada um dos parâmetros a serem ajustados. Para cada combinação, ela estima a performance do modelo em dados novos. Por fim, o modelo com melhor métrica de desempenho é escolhido. Tem-se então que este modelo é o que melhor pode vir a generalizar mediante dados nunca antes vistos.\n",
    "\n",
    "Nesta busca em grande, contemple a utilização do objeto [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron1 = [50, 75, 100]\n",
    "neuron2 = [10, 15]\n",
    "\n",
    "neurons = []\n",
    "for i in neuron1:\n",
    "  for j in neuron2:\n",
    "    neurons.append((i,j))\n",
    "\n",
    "neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'hidden_layer_sizes': neurons,\n",
    "    'activation': ['identity', 'logistic', 'tahn', 'relu'],\n",
    "    'solver': ['adam', 'lbfgs', 'sqd']\n",
    "}\n",
    "# Utilizando k-fold padrão de 5 e aumentando número de tentativas para 20\n",
    "# Total de 360 fits\n",
    "searcher = GridSearchCV(MLPClassifier(verbose=True, n_iter_no_change=20), parameters, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
